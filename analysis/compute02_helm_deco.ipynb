{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1fe8ca-c614-4f25-9144-2dd36bf4a9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/path/to/model/output/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5407aead-ad42-4158-958d-5c885f29dd15",
   "metadata": {},
   "source": [
    "# Helmholtz decomposition\n",
    "We want to perform a Helmholtz decomposition of $v'T'$ into its non-divergent and non-rotational parts ([](Marshall1981), [](Jayne2002)). The non-rotational part of $\\overrightarrow{\\mathbf{v}'T'}$ can be represented by a potential $\\phi$ with \n",
    "\\begin{equation}\n",
    "\\nabla^{2}\\phi = \\nabla\\cdot(\\overrightarrow{\\mathbf{v}'T'}),\n",
    "\\end{equation}\n",
    "such that\n",
    "\\begin{equation}\n",
    "\\label{eq:helm}\n",
    "\\begin{pmatrix}(u'T')_{div} \\\\ (v'T')_{div}\\end{pmatrix} = \\begin{pmatrix} \\frac{\\partial\\phi}{\\partial x} \\\\ \\frac{\\partial\\phi}{\\partial y}\\end{pmatrix}.\n",
    "\\end{equation}\n",
    "\n",
    "This equation is solved for $\\phi$ using Successive Over-Relaxation (SOR) with Neumann boundary conditions on the northern and southern boundaries (there are no boundary conditions at the western and eastern boundaries as the model is zonally periodic).\n",
    "\n",
    "\n",
    "## Compile the Fortran functions\n",
    "SOR is an iterative process and it is thus unavoidable to use loops. The main iterative loops are written in Fortran because they would be extremely slow in python. We compile them with `f2py` to use them within python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64314a2-0cc5-4fd0-8105-f3dc9aa9bac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source .venv/py_3/bin/activate; python3 -m numpy.f2py -c solve_poisson_SOR_black_NM.f95 -m solve_poisson_SOR_black_NM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b40e668-437d-420e-aef3-33715e86d0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source .venv/py_3/bin/activate; python3 -m numpy.f2py -c solve_poisson_SOR_red_NM.f95 -m solve_poisson_SOR_red_NM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453b098a-fda4-4c1f-921b-2de3060347bd",
   "metadata": {},
   "source": [
    "Import the compiled functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97864269-2ba1-4102-a814-d2321d5016fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import solve_poisson_SOR_black_NM\n",
    "import solve_poisson_SOR_red_NM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9af5d2e-bca4-4b4d-8931-1db989af7d9c",
   "metadata": {},
   "source": [
    "## Define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9122d46-d467-4c52-897a-6045375fb2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makegrid gives us some info about the grid that we need for the solver\n",
    "def makegrid(data_in, data_dx):\n",
    "    nx = data_in.shape[1]\n",
    "    ny = data_in.shape[0]\n",
    "    dx = data_dx\n",
    "    dy = dx\n",
    "    return (nx, ny, dx, dy)\n",
    "\n",
    "# set_bnd_phi sets the Neumann boundary conditions at the northern and southern boundary\n",
    "def set_bnd_phi(data):\n",
    "    data[0, :] = data[1, :]\n",
    "    data[-1, :] = data[-2, :]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9818d94f-be19-449c-849f-f497143540a9",
   "metadata": {},
   "source": [
    "The function `apply_SORphi` is the main function that applies SOR to solve for $\\phi$ at one time `t` and one depth level `k`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99db2766-dbe7-4abc-9916-1ebe1d61bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_SORphi(t):\n",
    "    # set desired residual error\n",
    "    residual = 1e-6\n",
    "    # set maximum allowed number of iterations\n",
    "    max_iter= 1e4\n",
    "    # extract the required time and depth from data and conver to Fortran order\n",
    "    npData = np.array(D[t, k, firstwet-1::, :], order='F')\n",
    "    if k == 0:\n",
    "        initial = init\n",
    "    else:\n",
    "        initial = init[t, :, :].squeeze()\n",
    "    # extend data in y direction to account for the boundaries\n",
    "    extend = np.zeros(npData.shape[1])\n",
    "    npData = np.vstack((npData, extend))\n",
    "    nx, ny, dx, dy = makegrid(npData, 10000.)\n",
    "    # set initial guess\n",
    "    if np.all(init == None):\n",
    "        data_out = np.zeros((ny, nx), order='F')\n",
    "    else:\n",
    "        data_out = np.array(initial, order='F')\n",
    "    # set omega (needs to be tuned depending on field to be solved)\n",
    "    om = 1.99\n",
    "    it = 1\n",
    "    res = 1\n",
    "    # iterate as long as the residual error is larger than `residual`\n",
    "    while( res  >= residual ):\n",
    "        pn = data_out.copy()\n",
    "        solve_poisson_SOR_black_NM.solve(npData, data_out, dx, dy, om, int(nx), int(ny))\n",
    "        solve_poisson_SOR_red_NM.solve(npData, data_out, dx, dy, om, int(nx), int(ny))\n",
    "        data_out = set_bnd_phi(data_out)\n",
    "        if pn.sum() == 0:\n",
    "            res = 1\n",
    "        else:\n",
    "            res = abs((pn.sum() - data_out.sum()) / pn.sum())\n",
    "        if it < max_iter:\n",
    "            it += 1\n",
    "        else:\n",
    "            break\n",
    "    return data_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a11d7a2-56b5-44ed-92ef-5b58a33d7b6c",
   "metadata": {},
   "source": [
    "## Loop over all times and depths\n",
    "Now we loop over all years and depth levels to perform the Helmholtz decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd28f3-6589-4395-88f5-4e488eac0b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the 10 decades\n",
    "for y in range(0, 10):\n",
    "    print(y)\n",
    "    y1 = \"02\" + str(y) + \"1\"\n",
    "    y2 = \"0\" + str(int(y1)+9)\n",
    "    # loop over each year in decade\n",
    "    for Y in range(int(y1), int(y2) + 1):\n",
    "        # load THT\n",
    "        THT = xr.open_mfdataset(path + \"post/THT.\" \n",
    "                                + y1 + \"_\" + y2 + \".nc\").sel(time=slice(\"0\" + str(Y) + \"-01-01\",\n",
    "                                                                        \"0\" + str(Y) + \"-12-30\"))\n",
    "        # do some extension do account for boundaries and set land values to NaN\n",
    "        Utmp = THT.THTu\n",
    "        U = np.zeros((np.shape(Utmp)[0], np.shape(Utmp)[1], np.shape(Utmp)[2] + 1, np.shape(Utmp)[3]))\n",
    "        U[:, :, 0:-1, :] = Utmp\n",
    "        for k in np.arange(0, np.shape(U)[1]):\n",
    "            firstwet = np.argmax(U[0, k, :, 0] != 0)\n",
    "            U[:, k, 0:firstwet, :] = np.nan\n",
    "        V = np.zeros(np.shape(U))\n",
    "        V[:, :, 0:-1, :] = THT.THTv\n",
    "        for k in np.arange(0, np.shape(V)[1]):\n",
    "            firstwet = np.argmax(V[0, k, :, 0] != 0)\n",
    "            V[:, k, 0:firstwet-1, :] = np.nan\n",
    "        # compute d(THT_u)/dx and d(THT_v)/dy\n",
    "        dUx = np.zeros(U.shape)\n",
    "        dUx[:, :, :, 0:-1] = (U[:, :, :, 1::] - U[:, :, :, 0:-1]) / 10000.\n",
    "        dUx[:, :, :, -1] = (U[:, :, :, 0] - U[:, :, :, -1]) / 10000.\n",
    "        dVy = np.zeros(U.shape)\n",
    "        dVy[:, :, 0:-1, :] = (V[:, :, 1::, :] - V[:, :, 0:-1, :]) / 10000.\n",
    "        dVy[:, :, -1, :] = (V[:, :, 0, :] - V[:, :, -1, :]) / 10000.\n",
    "        D = (dUx + dVy)[:, :, 0:-1, :]\n",
    "        D[np.isnan(D)] = 0\n",
    "        # initialize phi\n",
    "        phi = np.zeros((np.shape(D)[0], np.shape(D)[1],\n",
    "                        np.shape(D)[2]+1, np.shape(D)[3]))\n",
    "        # loop over each depth level\n",
    "        for k in np.arange(0, np.shape(D)[1]):\n",
    "            print(\"working on depth level\", k)\n",
    "            firstwet = np.argmax(D[0, k, :, 0] != 0)\n",
    "            if k == 0:\n",
    "                init = None\n",
    "            else:\n",
    "                init = phi[:, k-1, firstwet-1::, :].squeeze()\n",
    "            # perform SOR on as many cpus in parallel as possible\n",
    "            # (we leave 2 cpus for other things)\n",
    "            if __name__ == \"__main__\":\n",
    "                with mp.Pool(mp.cpu_count() - 2) as p:\n",
    "                    phi[:, k, firstwet-1::, :] = p.map(apply_SORphiNew, np.arange(0, np.shape(D)[0]))\n",
    "                p.close()\n",
    "                p.join()\n",
    "        phi[phi==0] = np.nan\n",
    "        # dphi/dy gives meridional component\n",
    "        vdiv = np.zeros(np.shape(D))\n",
    "        vdiv[:, :, 1::, :] = (phi[:, :, 1:-1, :] - phi[:, :, 0:-2, :]) / 10000.\n",
    "        ds_vdiv = xr.Dataset({\"time\": ([\"time\",], THT.time.data),\n",
    "                              \"Z\": ([\"Z\",], THT.Z.data),\n",
    "                              \"YG\": ([\"YG\",], THT.YG.data),\n",
    "                              \"XC\": ([\"XC\",], THT.XC.data)})\n",
    "        ds_vdiv[\"THTvdiv\"] = xr.DataArray(vdiv, dims=[\"time\", \"Z\", \"YG\", \"XC\"])\n",
    "        ds_vdiv.to_netcdf(path + \"post/THTvdiv.0\" + str(Y) + \".nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python eddytools",
   "language": "python",
   "name": "py_eddytools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
