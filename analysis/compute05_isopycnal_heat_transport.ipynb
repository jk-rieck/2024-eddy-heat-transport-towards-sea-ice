{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ad6640-537a-4474-9307-183ed126aafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask\n",
    "import xgcm\n",
    "import postmit as pm\n",
    "import seawater as sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faea0793-d294-4087-80ea-bb2740baeb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/path/to/model/output/\" \n",
    "eddypath = \"/path/to/tracked/eddies/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d92876-44e7-4e8d-89e3-44f48340c599",
   "metadata": {},
   "source": [
    "### Heat transport on isopycnals\n",
    "\n",
    "The meridional HT in isopycnal coordinates is computed following Lee et al., 2007. The velocity $v$ and temperature $T$ are mapped to isopycnal layers with thickness $h$, resulting in $v_{\\sigma}$ and $T_{\\sigma}$, and the total, time-averaged temperature transport can be decomposed such that\n",
    "\n",
    "$\\overline{v_{\\sigma}T_{\\sigma}h} = \\overline{v}_{eu}\\,\\hat{T_{\\sigma}}\\,\\overline{h} + \\overline{v}_{eddy}\\,\\hat{T_{\\sigma}}\\,\\overline{h} + \\widehat{v_{\\sigma}''\\,T_{\\sigma}''}\\,\\overline{h}$\n",
    "\n",
    "\n",
    "where $v_{eu}$ is the time-averaged meridional velocity in z-coordinates  mapped to mean isopycnal layers, the $\\hat{\\cdot}=\\frac{\\overline{(\\cdot\\,h)}}{\\overline{h}}$ is the layer thickness-weighted time average, the double-prime denotes a deviation thereof, and $v_{eddy} = \\hat{v}_{\\sigma} - \\overline{v}_{eu}$. The first term on the rhs is the mean temperature advection, the second term is the advection of temperature due to transient processes and the third term represents the diffusion by the transient processes. The advective component of the transient HT on isopycnals is thus\n",
    "\n",
    "$THT_{iso}^{adv}(y, r) = \\rho C_{p} [\\overline{v}_{eddy}\\,\\hat{T}_{\\sigma}\\,\\overline{h}]_{\\sigma} = \\rho C_{p} [\\frac{\\overline{v_{\\sigma}h}}{\\overline{h}}\\,\\overline{T_{\\sigma} h} - \\overline{v_{eu}}\\,\\overline{T_{\\sigma} h}]_{\\sigma}$\n",
    "\n",
    "where $r$ is the density-coordinate and $[\\cdot]_{\\sigma}$ indicates a zonal average along isopycnals. The diffusive part is represented by\n",
    "\n",
    "$THT_{iso}^{diff}(y, r) = \\rho C_{p} [\\widehat{v_{\\sigma}''\\,T_{\\sigma}''}\\,\\overline{h}]_{\\sigma} = \\rho C_{p} [\\overline{(v_{\\sigma} - \\frac{\\overline{v_{\\sigma} h}}{\\overline{h}}) (T_{\\sigma} - \\frac{\\overline{T_{\\sigma} h}}{\\overline{h}})\\,h}]_{\\sigma}$\n",
    "\n",
    "and the total transient, along-isopycnal HT is computed as\n",
    "\n",
    "$THT_{iso}(y, r) = THT_{iso}^{adv}(y, r) + THT_{iso}^{diff}(y, r)$\n",
    "\n",
    "\n",
    "To compute the contribution by coherent mesoscale eddies to the along-isopycnal heat transport, we again use the eddymasks:\n",
    "\n",
    "$THT_{iso}^{CME,adv}(y, r) = \\rho C_{p} [\\frac{\\overline{v_{\\sigma} M^{CME} h}}{\\overline{h}}\\,\\overline{T_{\\sigma} h} - \\overline{v_{eu}}\\,\\overline{T_{\\sigma} h}]_{\\sigma}$\n",
    " \n",
    "and\n",
    "\n",
    "$THT_{iso}^{CME,diff}(y, r) = \\rho C_{p} [\\overline{(v_{\\sigma} M^{CME} - \\frac{\\overline{v_{\\sigma} M^{CME} h}}{\\overline{h}}) (T_{\\sigma} - \\frac{\\overline{T_{\\sigma} h}}{\\overline{h}})\\,h}]_{\\sigma}$\n",
    "\n",
    "The total $THT_{iso}^{CME}$ is computed equivalently to before as\n",
    "\n",
    "$THT_{iso}^{CME}(y, r) = THT_{iso}^{CME,adv}(y, r) + THT_{iso}^{CME,diff}(y, r)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f932fd-9376-4f33-ba02-620ca3453c97",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "`convert2Zp1` interpolates a variable to the grid cell's faces. I.e. in MITgcm terms, from `Z` to `Zp1`. This is needed for the remapping to sigma-coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991c4396-cc51-46b4-a214-5d408404abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2Zp1(var, grid):\n",
    "    part1 = grid.interp(var, \"Z\", to=\"left\", boundary=\"extend\").rename({\"Zl\": \"Zp1\"})\n",
    "    part2 = grid.interp(var, \"Z\", to=\"right\", boundary=\"extend\").isel(Zu=slice(-1, None)).rename({\"Zu\": \"Zp1\"})\n",
    "    return xr.concat((part1, part2), dim=\"Zp1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4daaa67-6c03-4b89-80de-3f50defabeee",
   "metadata": {},
   "source": [
    "`param_and_prepare` sets parameters needed for the calculations and does som pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89e700b-d92c-4b35-a6ef-b1fe4f0e5bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_and_prepare(data):\n",
    "    # set constants\n",
    "    rho = 1035.\n",
    "    Cp = 3994.\n",
    "    # sigma-levels to map to later\n",
    "    target_rho_levelsC = np.hstack(([5., 15., 22.5, 27.5, 30.5, 31.5], \n",
    "                                    np.arange(32.05, 35., 0.1),\n",
    "                                    np.arange(35.025, 36., 0.05),\n",
    "                                    np.arange(36.01, 36.9, 0.02),\n",
    "                                    np.arange(36.905, 37.2, 0.01),\n",
    "                                    np.arange(37.21, 37.6, 0.02),\n",
    "                                    np.arange(37.605, 37.8, 0.01),\n",
    "                                    np.arange(37.825, 37.9, 0.05),\n",
    "                                    [37.95, 38.05, 38.2, 38.4, 38.75, 39.5, 42.5, 47.5, 75.]))\n",
    "    target_rho_levelsB = np.hstack(([0., 10., 20., 25., 30., 31.], \n",
    "                                    np.arange(32., 35., 0.1),\n",
    "                                    np.arange(35., 36., 0.05),\n",
    "                                    np.arange(36., 36.9, 0.02),\n",
    "                                    np.arange(36.9, 37.199, 0.01),\n",
    "                                    np.arange(37.2, 37.6, 0.02),\n",
    "                                    np.arange(37.6, 37.8, 0.01),\n",
    "                                    np.arange(37.8, 37.899, 0.05),\n",
    "                                    [37.9, 38., 38.1, 38.3, 38.5, 39., 40., 45., 50., 100.]))\n",
    "    # timestamp for the files to write to disk\n",
    "    savetime = data.time.isel(time=slice(int(len(data.time) / 2), int(len(data.time) / 2) + 1))\n",
    "    # compute the reference temperature (freezing point)\n",
    "    tref = sw.eos80.fp(data.SALT, 1.065)\n",
    "    # metrics of the Z-axis for the xgcm grid instance\n",
    "    metrics = {\n",
    "        ('Z'): ['drC', 'drF', 'drS', 'drW'], # Z distances\n",
    "    }\n",
    "    grid = xgcm.Grid(data, periodic=[\"X\"], metrics=metrics)\n",
    "    # calculate sigma_2\n",
    "    data = pm.calcs.sigi(data, 2)  \n",
    "    sigName = \"SIG2\"\n",
    "    # define dummy variables with sizes as THETA, VVEL etc. filled with ones\n",
    "    ones_gridT = (data.THETA / data.THETA)\n",
    "    ones_gridV = (data.VVEL / data.VVEL)\n",
    "    ones_gridZ = (grid.interp(data.VVEL, \"X\", boundary=\"extend\") / grid.interp(data.VVEL, \"X\", boundary=\"extend\"))\n",
    "    # define each levels (in depth-space) thickness\n",
    "    data[\"levThick_all\"] = (data.drF * data.hFacC * data.maskC).expand_dims(dim={\"time\": data.time})\n",
    "    # convert sigma_2 to cell faces (on Z-axis)\n",
    "    data[\"SIG2\"] = (data.SIG2 - 1000.).where(data.maskC == 1)\n",
    "    data[\"SIG2B\"] = convert2Zp1(data.SIG2, grid).chunk({\"time\": 72, \"Zp1\": 56, \"YC\": 320, \"XC\": 240})\n",
    "    # do the same for sigma_2 interpolated to V-points\n",
    "    data[\"SIG2v\"] = grid.interp(data.SIG2, \"Y\", boundary=\"extend\").rename(\"SIG2\")\n",
    "    data[\"SIG2vB\"] = convert2Zp1(data.SIG2v, grid).chunk({\"time\": 72, \"Zp1\": 56, \"YG\": 320, \"XC\": 240})\n",
    "    # and again for sigma_2 interpolate to F-points\n",
    "    data[\"SIG2z\"] = grid.interp(data.SIG2v, \"X\", boundary=\"extend\").rename(\"SIG2\")\n",
    "    data[\"SIG2zB\"] = convert2Zp1(data.SIG2z, grid).chunk({\"time\": 72, \"Zp1\": 56, \"YG\": 320, \"XG\": 240})\n",
    "    # define a mask that is \"1\" within the mean winter mixed layer and \"0\" elsewhere\n",
    "    data[\"xMLD\"] = ones_gridT.where(\n",
    "        -data.Z > data.MXLDEPTH.groupby(\"time.season\").mean(\"time\").mean(\"XC\").sel(season=\"JJA\")\n",
    "        ) \n",
    "    # get this mask also on the cell faces, V-points and F-points\n",
    "    data[\"xMLDB\"] = convert2Zp1(data.xMLD, grid).chunk({\"time\": 72, \"Zp1\": 56, \"YC\": 320, \"XC\": 240})\n",
    "    data[\"xMLDv\"] = ones_gridV.where(\n",
    "        -data.Z > grid.interp(data.MXLDEPTH.groupby(\"time.season\").mean(\"time\").mean(\"XC\").sel(season=\"JJA\"), \n",
    "                              \"Y\", boundary=\"extend\")\n",
    "        )\n",
    "    data[\"xMLDz\"] = ones_gridZ.where(\n",
    "        -data.Z > grid.interp(data.MXLDEPTH.groupby(\"time.season\").mean(\"time\").mean(\"XC\").sel(season=\"JJA\"), \n",
    "                              \"Y\", boundary=\"extend\")\n",
    "        )\n",
    "    return rho, Cp, target_rho_levelsC, target_rho_levelsB, savetime, tref, sigName, data, grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7105f4cb-ffac-4219-9966-79254048060c",
   "metadata": {},
   "source": [
    "`z2rho` maps a variable defined on z-levels to the given isopycnal levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b35ca1a-8f6c-43e5-b90e-743e37b8cf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z2rho(grid, var, target_levels, target_data, target_name, method):\n",
    "    var_rho = grid.transform(var, \"Z\", target_levels, target_data=target_data, method=method)\n",
    "    var_rho = var_rho.rename({target_name: \"layer_center\"})\n",
    "    return var_rho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abac4a3-e27a-4f63-b1b7-0883483ea78c",
   "metadata": {},
   "source": [
    "`calc_adviso` and `calc_adviso_eddy` are the functions calculating \n",
    "\n",
    "$THT_{iso}^{adv}(y, r) = \\rho C_{p} [\\overline{v}_{eddy}\\,\\hat{T}_{\\sigma}\\,\\overline{h}]_{\\sigma} = \\rho C_{p} [\\frac{\\overline{v_{\\sigma}h}}{\\overline{h}}\\,\\overline{T_{\\sigma} h} - \\overline{v_{eu}}\\,\\overline{T_{\\sigma} h}]_{\\sigma}$\n",
    "\n",
    "and \n",
    "\n",
    "$THT_{iso}^{CME,adv}(y, r) = \\rho C_{p} [\\frac{\\overline{v_{\\sigma} M^{CME} h}}{\\overline{h}}\\,\\overline{T_{\\sigma} h} - \\overline{v_{eu}}\\,\\overline{T_{\\sigma} h}]_{\\sigma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1fd9e0-4590-4a24-b443-1e1b11aa4b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_adviso(t, v, v_eu, h, h_bar, dx, grid, rho, Cp, season):\n",
    "    # calculate bar(T h) on F-points\n",
    "    thZ = grid.interp((t * h.data).groupby('time.month').mean(\"time\"), (\"X\", \"Y\"), boundary=\"extend\")\n",
    "    # get h and bar(h) on V-points\n",
    "    hV = grid.interp(h, \"Y\", boundary=\"extend\")\n",
    "    h_barV = grid.interp(h_bar, \"Y\", boundary=\"extend\")\n",
    "    # compute bar(v h) / bar(h) on F-points\n",
    "    vh_hZ = grid.interp((v * hV.data).groupby('time.month').mean(\"time\") / h_barV.data, (\"X\"), boundary=\"extend\")\n",
    "    vh_hZ = vh_hZ.where(~np.isnan(vh_hZ), other=0)\n",
    "    # get v_eu on F-points\n",
    "    v_euZ = grid.interp(v_eu, (\"X\"), boundary=\"extend\")\n",
    "    # compute THT^{adv}_{iso}\n",
    "    tht = (rho * Cp * ((thZ * vh_hZ) - (thZ * v_euZ)) * dx).sum(\"XG\")\n",
    "    # averaging over the whole seasonal cycle or just one season\n",
    "    if season==0:\n",
    "        out = tht.mean(\"month\")\n",
    "    elif season==\"DJF\":\n",
    "        out = tht.sel(month=[1, 2, 12]).mean(\"month\")\n",
    "    elif season==\"MAM\":\n",
    "        out = tht.sel(month=[3, 4, 5]).mean(\"month\")\n",
    "    elif season==\"JJA\":\n",
    "        out = tht.sel(month=[6, 7, 8]).mean(\"month\")\n",
    "    elif season==\"SON\":\n",
    "        out = tht.sel(month=[9, 10, 11]).mean(\"month\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c44800e-ccbc-4bf5-84a1-99511b531f21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_adviso_eddy(t, v, v_eu, h, h_bar, dx, season):\n",
    "    # get h on F-points\n",
    "    hZ = grid.interp(h, (\"X\", \"Y\"), boundary=\"extend\").data\n",
    "    # calculate bar(T h) on F-points\n",
    "    thZ = (t * hZ).groupby('time.month').mean(\"time\")\n",
    "    # compute bar(v h) / bar(h) on F-points\n",
    "    vh_hZ = (v * hZ).groupby('time.month').mean(\"time\") / grid.interp(h_bar, (\"X\", \"Y\"), boundary=\"extend\").data\n",
    "    vh_hZ = vh_hZ.where(~np.isnan(vh_hZ), other=0)\n",
    "    # get v_eu on F-points\n",
    "    v_euZ = grid.interp(v_eu, (\"X\"), boundary=\"extend\")\n",
    "    # compute THT^{CME,adv}_{iso}\n",
    "    tht = (rho * Cp * ((thZ * vh_hZ) - (thZ * v_euZ)) * dx).sum(\"XG\")\n",
    "    # averaging over the whole seasonal cycle or just one season\n",
    "    if season==0:\n",
    "        out = tht.mean(\"month\")\n",
    "    elif season==\"DJF\":\n",
    "        out = tht.sel(month=[1, 2, 12]).mean(\"month\")\n",
    "    elif season==\"MAM\":\n",
    "        out = tht.sel(month=[3, 4, 5]).mean(\"month\")\n",
    "    elif season==\"JJA\":\n",
    "        out = tht.sel(month=[6, 7, 8]).mean(\"month\")\n",
    "    elif season==\"SON\":\n",
    "        out = tht.sel(month=[9, 10, 11]).mean(\"month\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7814850e-2358-48b2-943d-6ec01f259a05",
   "metadata": {},
   "source": [
    "`calc_diffiso` and `calc_diffiso_eddy` compute  \n",
    "\n",
    "$THT_{iso}^{diff}(y, r) = \\rho C_{p} [\\widehat{v_{\\sigma}''\\,T_{\\sigma}''}\\,\\overline{h}]_{\\sigma} = \\rho C_{p} [\\overline{(v_{\\sigma} - \\frac{\\overline{v_{\\sigma} h}}{\\overline{h}}) (T_{\\sigma} - \\frac{\\overline{T_{\\sigma} h}}{\\overline{h}})\\,h}]_{\\sigma}$\n",
    "\n",
    "and \n",
    "\n",
    "$THT_{iso}^{CME,diff}(y, r) = \\rho C_{p} [\\overline{(v_{\\sigma} M^{CME} - \\frac{\\overline{v_{\\sigma} M^{CME} h}}{\\overline{h}}) (T_{\\sigma} - \\frac{\\overline{T_{\\sigma} h}}{\\overline{h}})\\,h}]_{\\sigma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874f7426-2d0f-480b-a98e-8769e9b8a828",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_diffiso(t, v, h, h_bar, dx, grid, rho, Cp, season):\n",
    "    # get h on V-points\n",
    "    hV = grid.interp(h, \"Y\", boundary=\"extend\")\n",
    "    # get h on F-points\n",
    "    hZ = grid.interp(h, (\"X\", \"Y\"), boundary=\"extend\")\n",
    "    # get bar(h) on V-points\n",
    "    h_barV = grid.interp(h_bar, \"Y\", boundary=\"extend\")\n",
    "    # get v on F-points\n",
    "    vZ = grid.interp(v, \"X\", boundary=\"extend\").groupby(\"time.month\")\n",
    "    # compute bar(v h) / bar(h) on F-points\n",
    "    vh_hZ = grid.interp((v * hV.data).groupby('time.month').mean(\"time\") / h_barV.data, (\"X\"), boundary=\"extend\")\n",
    "    vh_hZ = vh_hZ.where(~np.isnan(vh_hZ), other=0)\n",
    "    # get T on F-points\n",
    "    tZ = grid.interp(t, (\"X\", \"Y\"), boundary=\"extend\").groupby(\"time.month\")\n",
    "    # compute bar(T h) / bar(T) on F-points\n",
    "    th_hZ = grid.interp((t * h.data).groupby('time.month').mean(\"time\") / h_bar.data, (\"X\", \"Y\"), boundary=\"extend\")\n",
    "    th_hZ = th_hZ.where(~np.isnan(th_hZ), other=0)\n",
    "    # compute THT^{diff}_{iso}\n",
    "    tht = (rho * Cp * ((vZ - vh_hZ) * (tZ - th_hZ) * hZ.data) * dx).sum(\"XG\")\n",
    "    # averaging over the whole seasonal cycle or just one season\n",
    "    if season==0:\n",
    "        out = tht.mean(\"time\")\n",
    "    else:\n",
    "        out = tht.groupby(\"time.season\").mean(\"time\").sel(season=season)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d45a2-ee60-4f6e-b0d6-97ca589d616a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_diffiso_eddy(t, v, v_eddy, h, h_bar, dx, grid, rho, Cp, season):\n",
    "    # get h on V-points\n",
    "    hV = grid.interp(h, \"Y\", boundary=\"extend\")\n",
    "    # get h on F-points\n",
    "    hZ = grid.interp(h, (\"X\", \"Y\"), boundary=\"extend\")\n",
    "    # get bar(h) on F-points\n",
    "    h_barZ = grid.interp(h_bar, (\"X\", \"Y\"), boundary=\"extend\")\n",
    "    # get v M^CME\n",
    "    vZ_eddy = v_eddy.groupby(\"time.month\")\n",
    "    # compute bar(v M^CME h) / bar(h) on F-points\n",
    "    vh_hZ_eddy = (v_eddy * hZ.data).groupby('time.month').mean(\"time\") / h_barZ.data\n",
    "    vh_hZ_eddy = vh_hZ_eddy.where(~np.isnan(vh_hZ_eddy), other=0)\n",
    "    # get T on F-points\n",
    "    tZ = grid.interp(t, (\"X\", \"Y\"), boundary=\"extend\").groupby(\"time.month\")\n",
    "    # compute bar(T h) / bar(T) on F-points\n",
    "    th_hZ = grid.interp((t * h.data).groupby('time.month').mean(\"time\") / h_bar.data, (\"X\", \"Y\"), boundary=\"extend\")\n",
    "    th_hZ = th_hZ.where(~np.isnan(th_hZ), other=0)\n",
    "    # compute THT^{CME,diff}_{iso}\n",
    "    tht = (rho * Cp * ((vZ_eddy - vh_hZ_eddy) * (tZ - th_hZ) * hZ.data) * dx).sum(\"XG\")\n",
    "    # averaging over the whole seasonal cycle or just one season\n",
    "    if season==0:\n",
    "        out = tht.mean(\"time\")\n",
    "    else:\n",
    "        out = tht.groupby(\"time.season\").mean(\"time\").sel(season=season)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79f85bf-9273-4440-9646-453be969d15c",
   "metadata": {},
   "source": [
    "## Main function\n",
    "This function takes care of applying the previously defined ones to compute the different components of isopycnal heat transport following Leet et al., 2007."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64518b6-b8be-4485-a32b-c911d6365f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lee_eddy(data, em, em_anti, em_cyc, grid, sigma_name, rho, Cp, tref, target_rho_levelsC, target_rho_levelsB, excludeMLD=0, season=0):\n",
    "    # depending on whether we want to exclude the mixed layer or include only the mixed layer, we multiply the variables with the\n",
    "    # previously defined masks\n",
    "    with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "        if excludeMLD == 1:\n",
    "            xMLD = data[\"xMLD\"]\n",
    "            xMLDv = data[\"xMLDv\"]\n",
    "            xMLDb = data[\"xMLDB\"]\n",
    "            T = (data.THETA - tref) * xMLD\n",
    "            v = data.VVEL * xMLDv\n",
    "            sigma = (data.SIG2 * xMLD).rename(sigma_name)\n",
    "            sigmaV = (data.SIG2v * xMLDv).rename(sigma_name)\n",
    "            sigmaB = (data.SIG2B * xMLDb).rename(sigma_name)\n",
    "            monthly_sigmaV = (data.SIG2v * xMLDv).groupby('time.month').mean(\"time\").rename(sigma_name)\n",
    "            levThick = data.levThick_all * xMLD\n",
    "        elif excludeMLD == -1:\n",
    "            MLD = data[\"xMLD\"].fillna(1).where(((np.isnan(data[\"xMLD\"])) & (data.THETA != 0)))\n",
    "            MLDv = data[\"xMLDv\"].fillna(1).where(((np.isnan(data[\"xMLDv\"])) & (data.VVEL != 0)))\n",
    "            MLDb = data[\"xMLDB\"].fillna(1).where(((np.isnan(data[\"xMLDB\"])) & (data.SIG2B != 0)))\n",
    "            T = (data.THETA - tref) * MLD\n",
    "            v = data.VVEL * MLDv\n",
    "            sigma = (data.SIG2 * MLD).rename(sigma_name)\n",
    "            sigmaV = (data.SIG2v * MLDv).rename(sigma_name)\n",
    "            sigmaB = (data.SIG2B * MLDb).rename(sigma_name)\n",
    "            monthly_sigmaV = (data.SIG2v * MLDv).groupby('time.month').mean(\"time\").rename(sigma_name)\n",
    "            levThick = data.levThick_all * MLD\n",
    "        else:\n",
    "            T = (data.THETA - tref)\n",
    "            v = data.VVEL\n",
    "            sigma = (data.SIG2).rename(sigma_name)\n",
    "            sigmaV = (data.SIG2v).rename(sigma_name)\n",
    "            sigmaB = (data.SIG2B).rename(sigma_name)\n",
    "            monthly_sigmaV = data.SIG2v.groupby('time.month').mean(\"time\").rename(sigma_name)\n",
    "            levThick = data.levThick_all\n",
    "        # transform t and v to isopycnals\n",
    "        t_rho = z2rho(grid, T, target_rho_levelsC, sigma, sigma_name, \"linear\").chunk({\"time\": 72, \"YC\": 320, \"XC\": 240})\n",
    "        t_rho = t_rho.where(~np.isnan(t_rho), other=0)\n",
    "        # need t_rho on F-points as well\n",
    "        t_rhoZ = grid.interp(t_rho, (\"X\", \"Y\"), boundary=\"extend\")\n",
    "        v_rho = z2rho(grid, v, target_rho_levelsC, sigmaV, sigma_name, \"linear\").chunk({\"time\": 72, \"YG\": 320, \"XC\": 240})\n",
    "        v_rho = v_rho.where(~np.isnan(v_rho), other=0)\n",
    "        # multiply v_rho with the different eddymasks to calculate the CME contribution\n",
    "        v_rho_eddy = (grid.interp(v_rho, (\"X\"), boundary=\"extend\") * em).chunk({\"time\": 72, \"YG\": 320, \"XG\": 240})\n",
    "        v_rho_eddy = v_rho_eddy.where(~np.isnan(v_rho_eddy), other=0)\n",
    "        v_rho_eddy_cyc = (grid.interp(v_rho, (\"X\"), boundary=\"extend\") * em_cyc).chunk({\"time\": 72, \"YG\": 320, \"XG\": 240})\n",
    "        v_rho_eddy_cyc = v_rho_eddy_cyc.where(~np.isnan(v_rho_eddy_cyc), other=0)\n",
    "        v_rho_eddy_anti = (grid.interp(v_rho, (\"X\"), boundary=\"extend\") * em_anti).chunk({\"time\": 72, \"YG\": 320, \"XG\": 240})\n",
    "        v_rho_eddy_anti = v_rho_eddy_anti.where(~np.isnan(v_rho_eddy_anti), other=0)\n",
    "        # get level thicknesses of isopycnals \n",
    "        levThick_rho = z2rho(grid, levThick, target_rho_levelsB, sigmaB, sigma_name, \n",
    "                             \"conservative\").chunk({\"time\": 72, \"YC\": 320, \"XC\": 240})\n",
    "        levThick_rho = levThick_rho.where(~np.isnan(levThick_rho.data), other=0)\n",
    "        levThickbar_rho = levThick_rho.groupby('time.month').mean(\"time\")\n",
    "        levThick_rho_all = z2rho(grid, data.levThick_all, target_rho_levelsB, sigmaB, sigma_name, \n",
    "                                 \"conservative\").chunk({\"time\": 72, \"YC\": 320, \"XC\": 240})\n",
    "        levThick_rho_all = levThick_rho_all.where(~np.isnan(levThick_rho_all.data), other=0)\n",
    "        levThickbar_rho_all = levThick_rho_all.groupby('time.month').mean(\"time\")\n",
    "        # compute v_eu (eulerian mean v transformed to rho-space)\n",
    "        v_eu_z = v.groupby('time.month').mean(\"time\")\n",
    "        v_eu = z2rho(grid, v_eu_z, target_rho_levelsC, monthly_sigmaV, sigma_name, \"linear\")\n",
    "        v_eu = v_eu.where(~np.isnan(v_eu), other=0) \n",
    "        # compute advective part of transient ispycnal heat transport\n",
    "        adviso = calc_adviso(t_rho, v_rho, v_eu, levThick_rho, levThickbar_rho, data.dxV, grid, rho, Cp, season)\n",
    "        adviso_eddy = calc_adviso_eddy(t_rhoZ, v_rho_eddy, v_eu, levThick_rho, levThickbar_rho, data.dxV, season)\n",
    "        adviso_eddy_cyc = calc_adviso_eddy(t_rhoZ, v_rho_eddy_cyc, v_eu, levThick_rho, levThickbar_rho, data.dxV, season)\n",
    "        adviso_eddy_anti = calc_adviso_eddy(t_rhoZ, v_rho_eddy_anti, v_eu, levThick_rho, levThickbar_rho, data.dxV, season)\n",
    "        # compute diffusive part of transient isopycnal heat transport\n",
    "        diffiso = calc_diffiso(t_rho, v_rho, levThick_rho, \n",
    "                               levThickbar_rho, data.dxV, grid, rho, Cp, season)\n",
    "        diffiso_eddy = calc_diffiso_eddy(t_rho, v_rho, v_rho_eddy,\n",
    "                                         levThick_rho, levThickbar_rho, data.dxV, grid, rho, Cp, season)\n",
    "        diffiso_eddy_cyc = calc_diffiso_eddy(t_rho, v_rho, v_rho_eddy_cyc,\n",
    "                                             levThick_rho, levThickbar_rho, data.dxV, grid, rho, Cp, season)\n",
    "        diffiso_eddy_anti = calc_diffiso_eddy(t_rho, v_rho, v_rho_eddy_anti, \n",
    "                                              levThick_rho, levThickbar_rho, data.dxV, grid, rho, Cp, season)\n",
    "        # create dataset as output\n",
    "        THTiso_lee = adviso + diffiso\n",
    "        HTiso = xr.Dataset({\"THTiso_lee\": THTiso_lee, \n",
    "                            \"ADViso\": adviso,\n",
    "                            \"ADViso_eddy\": adviso_eddy,\n",
    "                            \"ADViso_eddy_anticyclones\": adviso_eddy_anti,\n",
    "                            \"ADViso_eddy_cyclones\": adviso_eddy_cyc,\n",
    "                            \"DIFFiso\": diffiso,\n",
    "                            \"DIFFiso_eddy\": diffiso_eddy,\n",
    "                            \"DIFFiso_eddy_cyclones\": diffiso_eddy_cyc,\n",
    "                            \"DIFFiso_eddy_anticyclones\": diffiso_eddy_anti,\n",
    "                            \"levThick\": ((\"YG\", \"layer_center\"), \n",
    "                                          grid.interp(levThickbar_rho_all.mean((\"XC\", \"month\")), \n",
    "                                                      \"Y\", boundary=\"extend\").data[:, :])})\n",
    "    return HTiso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87098f7-9e22-4502-9d82-dec2e756f37d",
   "metadata": {},
   "source": [
    "## Loop over decades\n",
    "\n",
    "We compute the heat transports for each decade of the 100 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb42d55f-5a0a-49e0-96d1-798980949671",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = np.arange(201, 300, 10)\n",
    "t2 = np.arange(210, 301, 10)\n",
    "for a, b in zip(t1, t2):\n",
    "    y1 = \"0\" + str(a)\n",
    "    y2 = \"0\" + str(b)\n",
    "    print(y1 + \" - \" + y2)\n",
    "    # loading the data and the eddymasks\n",
    "    data = xr.open_zarr(path + \"zarr_Diags/output.5d.zarr\").sel(time=slice(y1 + \"-01-01\", y2 + \"-12-30\"))\n",
    "    em = xr.open_mfdataset(eddypath + 'eddymask_0201-0300.nc').eddymask.squeeze().rename({\"lon\": \"XG\", \"lat\": \"YG\"})\n",
    "    em_cyc = xr.open_mfdataset(eddypath + 'eddymask_cyclones_0201-0300.nc').eddymask_cyclones.squeeze().rename({\"lon\": \"XG\", \"lat\": \"YG\"})\n",
    "    em_anti = xr.open_mfdataset(eddypath + 'eddymask_anticyclones_0201-0300.nc').eddymask_anticyclones.squeeze().rename({\"lon\": \"XG\", \"lat\": \"YG\"})\n",
    "    # pre-process data and get constants and parameters\n",
    "    rho, Cp, targetC, targetB, savetime, tref, sigName, data, grid = param_and_prepare(data)\n",
    "    data = data.drop(\"season\")\n",
    "    # loop over mean seasonal cycle (season=0) and the four seasons\n",
    "    seasons = [0, \"DJF\", \"MAM\", \"JJA\", \"SON\"]\n",
    "    for season in seasons:\n",
    "        if season == 0:\n",
    "            print(\"annual mean\")\n",
    "            s = \".\"\n",
    "        else:\n",
    "            print(season)\n",
    "            s = \".\" + season + \".\"\n",
    "        HTiso = lee_eddy(data, em, em_anti, em_cyc, grid, sigName, rho, Cp, tref, targetC, targetB, excludeMLD=0, season=season)\n",
    "        HTiso = HTiso.expand_dims({\"time\": savetime}).chunk({\"time\": 1, \"YG\": 320, \"layer_center\": 182})\n",
    "        HTiso.to_netcdf(path + \"post/HTiso_eddy\" + s + y1 + \"_\" + y2 + \".nc\")\n",
    "        ## Exlude the Mixed Layer   \n",
    "        HTisoNoMLjja = lee_eddy(data, em, em_anti, em_cyc, grid, sigName, rho, Cp, tref, targetC, targetB, excludeMLD=1, season=season)\n",
    "        HTisoNoMLjja = HTisoNoMLjja.expand_dims({\"time\": savetime}).chunk({\"time\": 1, \"YG\": 320, \"layer_center\": 182})\n",
    "        HTisoNoMLjja.to_netcdf(path + \"post/HTisoNoMLjja_eddy.\" + s + y1 + \"_\" + y2 + \".nc\")\n",
    "        ## Only Mixed Layer\n",
    "        HTisoMLjja = lee_eddy(data, em, em_anti, em_cyc, grid, sigName, rho, Cp, tref, targetC, targetB, excludeMLD=-1, season=season)\n",
    "        HTisoMLjja = HTisoMLjja.expand_dims({\"time\": savetime}).chunk({\"time\": 1, \"YG\": 320, \"layer_center\": 182})\n",
    "        HTisoMLjja.to_netcdf(path + \"post/HTisoMLjja_eddy.\" + s + y1 + \"_\" + y2 + \".nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python eddytools",
   "language": "python",
   "name": "py_eddytools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
